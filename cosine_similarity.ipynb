{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Cosine simmilarity between embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from eval import getembeddings\n",
    "\n",
    "embedding_dir = os.path.join('data', 'embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\embeddings\\*\\bentham\\*_002_080_001.pt\n",
      "['data\\\\embeddings\\\\ground_truth\\\\bentham\\\\GT_002_080_001.pt', 'data\\\\embeddings\\\\ocr\\\\bentham\\\\ocr_002_080_001.pt', 'data\\\\embeddings\\\\test\\\\bentham\\\\test_002_080_001.pt']\n",
      "['data\\\\embeddings\\\\ocr\\\\bentham\\\\ocr_002_080_001.pt', 'data\\\\embeddings\\\\test\\\\bentham\\\\test_002_080_001.pt']\n",
      "ocr\n",
      "Cosine Similarity: 0.6028253436088562\n",
      "test\n",
      "Cosine Similarity: 0.9981483221054077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jnicolow\\AppData\\Local\\Temp\\ipykernel_19644\\3531187463.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  gt_embedding = torch.load(gt_embedding_fn)\n",
      "C:\\Users\\jnicolow\\AppData\\Local\\Temp\\ipykernel_19644\\3531187463.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  other_embedding = torch.load(embedding_fn)\n",
      "C:\\Users\\jnicolow\\AppData\\Local\\Temp\\ipykernel_19644\\3531187463.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  other_embedding = torch.load(embedding_fn)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "gt_embedding_fns = glob(os.path.join(embedding_dir, 'ground_truth', 'bentham', '*.pt'))\n",
    "\n",
    "for gt_embedding_fn in gt_embedding_fns:\n",
    "    gt_embedding = torch.load(gt_embedding_fn)\n",
    "    \n",
    "    # get other embeddings\n",
    "    print(os.path.join(embedding_dir, '*', 'bentham', f\"*{os.path.basename(gt_embedding_fn).replace('GT', '')}\"))\n",
    "    other_embedding_fns = glob(os.path.join(embedding_dir, '*', 'bentham', f\"*{os.path.basename(gt_embedding_fn).replace('GT', '')}\"))\n",
    "    print(other_embedding_fns)\n",
    "    other_embedding_fns = [f for f in other_embedding_fns if \"ground_truth\" not in os.path.dirname(f)] # remove ground truth\n",
    "    print(other_embedding_fns)\n",
    "    for embedding_fn in other_embedding_fns:\n",
    "        other_embedding = torch.load(embedding_fn)\n",
    "        similarity = cosine_similarity(gt_embedding.reshape(1, -1), other_embedding.reshape(1, -1))\n",
    "        print(os.path.basename(os.path.dirname(os.path.dirname(embedding_fn))))\n",
    "        print(f\"Cosine Similarity: {similarity[0][0]}\")\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jnicolow\\AppData\\Local\\anaconda3\\envs\\ocr\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97447133]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9660716652870178, 0.8941878080368042, 0.8949460983276367]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from eval import getembeddings\n",
    "from eval import gpuutils\n",
    "from eval import cosinesim\n",
    "\n",
    "import importlib\n",
    "importlib.reload(getembeddings)\n",
    "importlib.reload(cosinesim)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "device = gpuutils.get_gpu_most_memory()\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "gt = \"I dont want no food\"\n",
    "pred = \"No I dont want food\"\n",
    "\n",
    "print(cosinesim.get_cosine_sim_bert_single(gt, pred, model, tokenizer, device=device))\n",
    "\n",
    "gts = [['what the '], ['chicken little'], ['vegan queen']]\n",
    "preds = [['what?'], ['little bird'], ['snowflake']]\n",
    "\n",
    "cosinesim.get_cosine_sim_bert(gt_arr = gts, pred_arr = preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"\"\"\n",
    "1. Other Propaganda Theorists\n",
    "1.1 Harold Lasswell (1902-1978)\n",
    "As Lippmann was writing propaganda, Harold Lasswell was undertaking empirical analyses of propaganda. In fact, much of the propaganda that Lasswell was examining was actually being written by Lippmann himself (Rogers, 1994).\n",
    "\n",
    "Harold Lasswell (1902-1978) was a prominent scholar in the area of propaganda research. He focused on conducting both quantitative and qualitative analyses of propaganda, and discovering the effect of propaganda on the mass audience (Rogers, 1994). Lasswell is credited with creating the mass communication procedure of content analysis (Rogers, 1944). Generally, content analysis can be defined as, \"...the investigation of communication messages by categorizing message content into classifications in order to measure certain variables” (Rogers, 1954).\n",
    "\n",
    "In an essay entitled \"Contents of Communication,” Lasswell (1946) explains that content analysis should take into account the frequency with which certain symbols appear in a message, the direction in which the symbols try to persuade the audience's opinion, and the intensity of the symbols used. By understanding the content of the message, Lasswell (1946) aims to achieve the goal of understanding the “stream of influence that runs from control to content and from content to audience” (p. 74).\n",
    "\n",
    "This method of content analysis is tied strongly to Lasswell's (1953) early definition of communication, which stated, “Who says what in which channel to whom and with what effects\" (p. 84). Content analysis was essentially the “says what” part of this definition, and Lasswell went on to do a lot of work within this area during the remainder of his career.\n",
    "\n",
    "Aside from understanding the content of propaganda, Lasswell was also interested in how propaganda could shape public opinion. This dealt primarily with understanding the effects of the media. Lasswell was particularly interested in examining the effects of the media in creating public opinion within a democratic system. In this way, Lasswell has created a cycle, whereby the public is limited in the information that is presented to them, and also apprehensive to accept it. However, it is still that information that is affecting their decisions within the democratic system, and is being presented to them by the government. This is an interesting way of viewing the power of the media that is somewhat similar to Lippmann’s theories.\n",
    "\n",
    "1.2 Edward Bernays (1891-1995)\n",
    "At approximately the same time that Lippmann and Lasswell were examining public opinion and propaganda, Edward Bernays (1891-1955) was examining public relations, propaganda, and public opinion. Bernays (1925) defines propaganda as, “a consistent, enduring effort to create or shape events to influence the relations of a public to an enterprise, idea, or group.”\n",
    "\n",
    "Bernays states, “We are governed, our minds are molded, our tastes formed, our ideas suggested, largely by men we have never heard of... Vast numbers of human beings must cooperate in this manner if they are to live together as a smoothly functioning society” (p. 37).\n",
    "\n",
    "Bernays believed that propaganda, when understood in its proper sense, was an essential part of a functioning society. He emphasized the importance of understanding the attitudes of various groups in society, gathering information, and using this knowledge to influence public opinion in the intended direction.\n",
    "\n",
    "Both of these theorists represent a step forward for mass communication theory. They moved away from more mechanical presentations of \"sit-down\" propaganda and moved toward a deeper understanding of the complex processes involved in shaping public opinion and behavior.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [20:53,  6.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw had a sim score of 0.9520036578178406 while gpt parsed ahd 0.922173798084259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "with open('openai_api_key.txt', \"r\") as file:  \n",
    "        openai.api_key = file.read()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai.api_key\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),  # This is the default and can be omitted\n",
    ")\n",
    "\n",
    "data_dir = r'C:\\Users\\jnicolow\\Documents\\courses\\fall2024\\ICS-661\\final project\\sampleDataset'\n",
    "gt_dir = os.path.join(data_dir, 'input_sample_groundtruth')\n",
    "# pred_dir = os.path.join(data_dir, 'ocr_output_scalefactor4')\n",
    "# pred_dir = os.path.join(data_dir, 'ocr_output_scalefactor6')\n",
    "\n",
    "pred_dirs = [os.path.join(data_dir, 'ocr_output')]#os.path.join(data_dir, 'ocr_output_scalefactor4'), os.path.join(data_dir, 'ocr_output_scalefactor6')]\n",
    "\n",
    "gt_fns = glob(os.path.join(gt_dir, '*.txt'))\n",
    "\n",
    "for pred_dir in pred_dirs:\n",
    "    ocr_cosine_sim_list = []\n",
    "    gpt_cosine_sim_list = []\n",
    "\n",
    "    for i, gt_fn in tqdm(enumerate(gt_fns)):\n",
    "        pred_fn = os.path.join(pred_dir, os.path.basename(gt_fn))\n",
    "        if os.path.join(pred_fn):\n",
    "            with open(gt_fn, \"r\") as file:  \n",
    "                gt_text = file.read()\n",
    "            \n",
    "            with open(pred_fn, \"r\") as file:  \n",
    "                pred_text = file.read()\n",
    "\n",
    "            \n",
    "            ocr_cosine_sim = cosinesim.get_cosine_sim_bert_single(gt_text, pred_text, model, tokenizer, device=device)\n",
    "\n",
    "            # clean up using gpt 3.5\n",
    "            chat_completion = client.chat.completions.create(\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"Dont add anything just clean grammar and fill missing text. then return only the cleaned text: {pred_text}\",\n",
    "                    }\n",
    "                ],\n",
    "                model=\"gpt-3.5-turbo\",  \n",
    "            )\n",
    "\n",
    "            assistant_reply = chat_completion.choices[0].message.content\n",
    "\n",
    "            save_dir = os.path.join(data_dir, f'gptcleaned_{os.path.basename(os.path.dirname(pred_fn))}')\n",
    "            if not os.path.exists(save_dir): os.mkdir(save_dir)\n",
    "            save_path = os.path.join(save_dir, os.path.basename(pred_fn))\n",
    "            with open(save_path, \"w\") as file:\n",
    "                file.write(assistant_reply)\n",
    "        \n",
    "            gpt_cosine_sim = cosinesim.get_cosine_sim_bert_single(gt_text, assistant_reply, model, tokenizer, device=device)\n",
    "            ocr_cosine_sim_list.append(ocr_cosine_sim)\n",
    "            gpt_cosine_sim_list.append(gpt_cosine_sim)\n",
    "\n",
    "        if i == 200: break # do first two hundred\n",
    "\n",
    "    # save similarity lists\n",
    "    joblib.dump(ocr_cosine_sim_list, os.path.join(data_dir, f\"ocr_cosine_sim_list_{os.path.basename(os.path.dirname(pred_fn))}.pkl\"))\n",
    "    joblib.dump(gpt_cosine_sim_list, os.path.join(data_dir, f\"gpt_cosine_sim_list_{os.path.basename(os.path.dirname(pred_fn))}.pkl\"))\n",
    "\n",
    "    print(f'Raw had a sim score of {np.mean(ocr_cosine_sim_list)} while gpt parsed got {np.mean(gpt_cosine_sim_list)}')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is corrupt text in this document.\n"
     ]
    }
   ],
   "source": [
    "ocr_output = 'Thesfe is curropt test in this docujment'\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"clean this text, return only the cleaned text: {ocr_output}\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",  \n",
    ")\n",
    "\n",
    "assistant_reply = chat_completion.choices[0].message.content\n",
    "print(assistant_reply)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
