{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR postprocessing via openai Chat GPT3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "from eval import cosinesim\n",
    "\n",
    "with open('openai_api_key.txt', \"r\") as file:  \n",
    "        openai.api_key = file.read()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai.api_key\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),  # This is the default and can be omitted\n",
    ")\n",
    "\n",
    "data_dir = r''\n",
    "gt_dir = os.path.join(data_dir, 'input_sample_groundtruth')\n",
    "# pred_dir = os.path.join(data_dir, 'ocr_output_scalefactor4')\n",
    "# pred_dir = os.path.join(data_dir, 'ocr_output_scalefactor6')\n",
    "\n",
    "pred_dirs = [os.path.join(data_dir, 'ocr_output'), os.path.join(data_dir, 'ocr_output_scalefactor4'), os.path.join(data_dir, 'ocr_output_scalefactor6')]\n",
    "\n",
    "gt_fns = glob(os.path.join(gt_dir, '*.txt'))\n",
    "\n",
    "for pred_dir in pred_dirs:\n",
    "    ocr_cosine_sim_list = []\n",
    "    gpt_cosine_sim_list = []\n",
    "\n",
    "    for i, gt_fn in tqdm(enumerate(gt_fns)):\n",
    "        if i <= 200: continue\n",
    "        pred_fn = os.path.join(pred_dir, os.path.basename(gt_fn))\n",
    "        if os.path.join(pred_fn):\n",
    "            with open(gt_fn, \"r\") as file:  \n",
    "                gt_text = file.read()\n",
    "            \n",
    "            with open(pred_fn, \"r\") as file:  \n",
    "                pred_text = file.read()\n",
    "\n",
    "            \n",
    "            # ocr_cosine_sim = cosinesim.get_cosine_sim_bert_single(gt_text, pred_text, model, tokenizer, device=device)\n",
    "\n",
    "            # clean up using gpt 3.5\n",
    "            chat_completion = client.chat.completions.create(\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"The following test is from ocr. There are some errors please fix them and return the text with no additional correspondence. Here are some examples: \\n raw: As Lipperean was writing propaganda, Harald Lasewell was ondenaking empirical aralywes of propaganda. La fect, munca af the propagemila that Lasswell wees gaining us actually being writes by Lippresnn Hints [Regers, [P. \\n cleaned: As Lippmann was writing propaganda, Harold Lasswell was undertaking empirical analyses of propaganda. In fact, much of the propaganda that Lasswell was examining was actually being written by Lippmann himself (Rogers, 1994). \\n raw: Vaderstantieg of the nate peble:, and the wesesaity od pomp S ¢Eseragt, 1668, p22]. Encrnyn (1686) Limeel sede sine prepaeea tts ‘m inffueasing the engineering of concent. \\n cleaned: Understanding of the public, and the necessity of attention-generating propaganda in influencing public opinion (Bernays, 1955, p.22). Bernays (1955) himself made a statement regarding his phrase, the engineering of consent public opinion (Bernays, 1955, p.22). \\n raw: The theories developed by Lippmann, Lospwell, Eilul, and Bernays are importand jor a emuiree reasons. \\n cleaned: The theories developed by Lippmann, Lasswell, Ellul, and Bernays are important for a number of reasons. \\n now do that for this:  {pred_text}\",\n",
    "                    }\n",
    "                ],\n",
    "                model=\"gpt-3.5-turbo\",  \n",
    "            )\n",
    "\n",
    "            assistant_reply = chat_completion.choices[0].message.content\n",
    "\n",
    "            save_dir = os.path.join(data_dir, f'gptcleaned_{os.path.basename(os.path.dirname(pred_fn))}')\n",
    "            if not os.path.exists(save_dir): os.mkdir(save_dir)\n",
    "            save_path = os.path.join(save_dir, os.path.basename(pred_fn))\n",
    "            with open(save_path, \"w\") as file:\n",
    "                file.write(assistant_reply)\n",
    "        \n",
    "            gpt_cosine_sim = cosinesim.get_cosine_sim_bert_single(gt_text, assistant_reply, model, tokenizer, device=device)\n",
    "            # ocr_cosine_sim_list.append(ocr_cosine_sim)\n",
    "            gpt_cosine_sim_list.append(gpt_cosine_sim)\n",
    "\n",
    "        if i == 400: break # do first two hundred\n",
    "\n",
    "    # save similarity lists\n",
    "    joblib.dump(ocr_cosine_sim_list, os.path.join(data_dir, f\"ocr_cosine_sim_list_{os.path.basename(os.path.dirname(pred_fn))}.pkl\"))\n",
    "    joblib.dump(gpt_cosine_sim_list, os.path.join(data_dir, f\"gpt_cosine_sim_list_{os.path.basename(os.path.dirname(pred_fn))}.pkl\"))\n",
    "\n",
    "    print(f'Raw had a sim score of {np.mean(ocr_cosine_sim_list)} while gpt parsed got {np.mean(gpt_cosine_sim_list)}')\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
